--- git status ---
On branch master
Your branch is up to date with 'origin/master'.

Changes not staged for commit:
  (use "git add <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   scripts/rsl_rl/__pycache__/cli_args.cpython-311.pyc
	modified:   source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env.py
	modified:   source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env_cfg.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	reference/rough_terrain_env.py
	reference/rough_terrain_env_cfg.py

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/scripts/rsl_rl/__pycache__/cli_args.cpython-311.pyc b/scripts/rsl_rl/__pycache__/cli_args.cpython-311.pyc
index cfe10a7..f2cdd8a 100644
Binary files a/scripts/rsl_rl/__pycache__/cli_args.cpython-311.pyc and b/scripts/rsl_rl/__pycache__/cli_args.cpython-311.pyc differ
diff --git a/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env.py b/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env.py
index 385a744..03a67f4 100644
--- a/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env.py
+++ b/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env.py
@@ -251,6 +251,10 @@ class Rob6323Go2Env(DirectRLEnv):
         joint_vel = self.robot.data.default_joint_vel[env_ids]
         default_root_state = self.robot.data.default_root_state[env_ids]
         default_root_state[:, :3] += self._terrain.env_origins[env_ids]
+        # # === ADDED: Random XY offsets to spread robots across terrain tiles ===
+        # # Terrain size is 8.0x8.0, env_spacing is 4.0, so offset within ~-1.5 to 1.5 to stay within tile
+        # xy_offset = torch.zeros(len(env_ids), 2, device=self.device).uniform_(-1.5, 1.5)
+        # default_root_state[:, :2] += xy_offset
         self.robot.write_root_pose_to_sim(default_root_state[:, :7], env_ids)
         self.robot.write_root_velocity_to_sim(default_root_state[:, 7:], env_ids)
         self.robot.write_joint_state_to_sim(joint_pos, joint_vel, None, env_ids)
diff --git a/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env_cfg.py b/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env_cfg.py
index fb5856c..915aac1 100644
--- a/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env_cfg.py
+++ b/source/rob6323_go2/rob6323_go2/tasks/direct/rob6323_go2/rob6323_go2_env_cfg.py
@@ -20,6 +20,10 @@ from isaaclab.markers.config import BLUE_ARROW_X_MARKER_CFG, FRAME_MARKER_CFG, G
 # === ADDED: PD controller import ===
 from isaaclab.actuators import ImplicitActuatorCfg
 
+# === ADDED: Rough terrain imports ===
+import isaaclab.terrains as terrain_gen
+from isaaclab.terrains.terrain_generator_cfg import TerrainGeneratorCfg
+
 @configclass
 class Rob6323Go2EnvCfg(DirectRLEnvCfg):
     # env
@@ -32,7 +36,7 @@ class Rob6323Go2EnvCfg(DirectRLEnvCfg):
     state_space = 0
     debug_vis = True
     # === ADDED: Base height termination threshold ===
-    base_height_min = 0.15
+    base_height_min = 0.05
 
     # simulation
     sim: SimulationCfg = SimulationCfg(
@@ -46,16 +50,50 @@ class Rob6323Go2EnvCfg(DirectRLEnvCfg):
             restitution=0.0,
         ),
     )
+    # terrain = TerrainImporterCfg(
+    #     prim_path="/World/ground",
+    #     terrain_type="plane",
+    #     collision_group=-1,
+    #     physics_material=sim_utils.RigidBodyMaterialCfg(
+    #         friction_combine_mode="multiply",
+    #         restitution_combine_mode="multiply",
+    #         static_friction=1.0,
+    #         dynamic_friction=1.0,
+    #         restitution=0.0,
+    #     ),
+    #     debug_vis=False,
+    # )
+
+
+    # === MODIFIED: Simple rough terrain config (mostly random_rough with low noise) ===
     terrain = TerrainImporterCfg(
         prim_path="/World/ground",
-        terrain_type="plane",
+        terrain_type="generator",
+        terrain_generator=TerrainGeneratorCfg(
+            size=(20.0, 20.0), #(8.0, 8.0)
+            border_width=0.0, #20.0
+            num_rows=1, #10
+            num_cols=1, #20
+            horizontal_scale=0.1,
+            vertical_scale=0.005,
+            slope_threshold=0.75,
+            use_cache=False,
+            sub_terrains={
+                "random_rough": terrain_gen.HfRandomUniformTerrainCfg(
+                    proportion=1.0,  # 100% random rough terrain (continuous, simple)
+                    noise_range=(0.01, 0.04),  # Low noise range (1-4cm) for simple terrain
+                    noise_step=0.01,
+                    border_width=0.25,
+                ),
+            },
+        ),
+        max_init_terrain_level=5,  # Start with easier terrains
         collision_group=-1,
         physics_material=sim_utils.RigidBodyMaterialCfg(
             friction_combine_mode="multiply",
             restitution_combine_mode="multiply",
             static_friction=1.0,
             dynamic_friction=1.0,
-            restitution=0.0,
         ),
         debug_vis=False,
     )
@@ -102,9 +140,9 @@ class Rob6323Go2EnvCfg(DirectRLEnvCfg):
     # === ADDED: Action rate penalty ===
     action_rate_reward_scale = -0.1
     # === ADDED: Raibert heuristic ===
-    raibert_heuristic_reward_scale = -10.0
+    raibert_heuristic_reward_scale = -0.0 # -10.0
     # === ADDED: Orientation penalty ===
-    orient_reward_scale = -5.0
+    orient_reward_scale = 0.0  # -5.0
     # === ADDED: Vertical velocity penalty ===
     lin_vel_z_reward_scale = -0.5
     # === ADDED: Joint velocity penalty ===
@@ -112,7 +150,7 @@ class Rob6323Go2EnvCfg(DirectRLEnvCfg):
     # === ADDED: Angular velocity penalty (roll/pitch) ===
     ang_vel_xy_reward_scale = -0.001
     # === ADDED: Feet clearance penalty ===
-    feet_clearance_reward_scale = -30.0
+    feet_clearance_reward_scale = -30.0 # -30.0
     # === ADDED: Contact tracking shaped force ===
-    tracking_contacts_shaped_force_reward_scale = 4.0
+    tracking_contacts_shaped_force_reward_scale = 0.0
 